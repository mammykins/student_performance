---
title: "Student_Performance_DT"
author: "Matthew Gregory"
date: "Monday, September 14, 2015"
output: html_document
---
# Student performance in Portugal  
Education is a key factor affecting long term economic progress. Success in the core languages provide a linguistic and numeric scaffold for other subjects later in students' academic careers.The growth in school educational databases facilitates the use of Data Mining and Machine Learning practises to improve outcomes in these subjects by identifying factors that are indicative of failure. Predicting outcomes allows educators to take corrective measures for weak students mitigating the risk of failure. 

## The Data  
The data was downloaded from the UCI Machine Learning database (see readme) and inspired by Cortez *et al*., 2008. We use maths results data only.

```{r, echo = FALSE, warning = FALSE}

#SETUP
rm(list = ls()) #clear workspace

setwd("C://Users//mammykins//Google Drive//R//student_cortez") #set wd
getwd() #check wd has been changed, make sure file is here

#PACKAGES
if(!require("dplyr")) {
  install.packages("dplyr")
  require("dplyr")
}  # if dplyr is not installed, install it then load it

if(!require("C50")) {
  install.packages("C50")
  require("C50")
} 

if(!require("gmodels")) {
  install.packages("gmodels")
  require("gmodels")
} 

#INPUT
mydata <- "student-mat.csv" 
mydata <- read.table(mydata, sep = ";",
                     header = TRUE) 
```
Let's have a look at our data using the convenient `glimpse` courtesy of the dplyr package. Notice how the range of the numeric variables is different.

```{r}
glimpse(mydata)
```

From the codebook we know that G3 is the final grade of the students. We can inspect it's distribution using a `hist`.

```{r, echo = FALSE}
hist(mydata$G3)

```

## Make the final grade binary (pass and fail)
G3 is pretty normally distributed, despite the dodgy tail. To simplify matters converted G3 marks below 10 as a fail, above or equal to 10 as a pass. Often a school is judged by whether students meet a critcal boundary, in the UK it is a C grade at GCSE for example.

```{r, echo = TRUE}
mydata$final <- NULL
mydata$final <- factor(ifelse(mydata$G3 >= 10, 1, 0),
                       labels = c("fail", "pass")) 
```

## Normalising the data
The numeric variables cover different ranges. As we want all variables to be treated the same we should convert them so that they range between zero and one, thus operating on the same scale. We are interested in relative differences not absolute.  
Our custom `normalise` function takes a vector x of numeric values, and for each value in x subtracts the min value in x and divides by the range of values in x. A vector is returned.
```{r}
normalise <- function(x) {
  return((x - min(x)) / (max(x) - min(x)))
}
```

## Objective  
- is it possible to predict student performance?    
- can we identify the important variables in determining intervention?   

## Decision tree advantages  
- Appropriate as students and parent will want to know why a student has been selected for intervention. The outcome is essentially a flowchart.  
- Widely used.  
- Decent performance.  
- There arn't too many variables in this problem.  
```{r, echo=FALSE}
set.seed(1337)
#data_rand <- tbl_df(mydata[order(runif(395)), ]) #  no need

#what variables are we interested in?
data_interest <-select(mydata, school, sex, G1, G2, Mjob, Fjob, goout, 
       absences, reason, Fjob, Mjob, failures, Fedu, Medu, final)

#normalise the data so they are on the same scale
#can you find a faster way to apply a function to each column
data_interest$G1 <- normalise(data_interest$G1)
data_interest$G2 <- normalise(data_interest$G2)
data_interest$goout <- normalise(data_interest$goout)
data_interest$absences <- normalise(data_interest$absences)
data_interest$failures <- normalise(data_interest$failures)
data_interest$Fedu <- normalise(data_interest$Fedu)
data_interest$Medu <- normalise(data_interest$Medu)
```
## Training and test datasets.
We need to split the data so we can build the model and then test it, to see if it generalises well. The data arrived in a random order.

```{r, echo = TRUE}
data_train <- data_interest[1:350, ]
data_test <- data_interest[351:395, ]
```

Now we need to train the model using the data.
```{r}
#Build the classifier
m <- C5.0(x = data_train[-13], y = data_train$final) 
#  final is the class variable so we need to exclude it from training
summary(m)
```
only 5% error rate, and the model has described an obvious relationship between most recent test score, G2, but has also identified the father's job as being a useful indicator which may not have got revealed in a human expert analysis .  
Let's see how generalisable the model is by comparing it's predicted student math G3 outcomes to real pass or fail status.

```{r}
#PREDICT
p <- predict(m, data_test)
CrossTable(data_test$final, p, prop.chisq = FALSE,
           prop.c = FALSE, prop.r = FALSE, dnn = c("actual pass",
                                                   "predicted pass"))
```
93.4% model accuracy not bad, 3 students proved us wrong and passed anyway! Seems like a useful model for identifying students who need extra intervention and importantly it can be applied and interpreted by a human. We should also look to improve the model, but we will leave that for another time. Not bad for an hours work.